{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "midterm_evaluation_2016320145.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9x9BnCps8rQt"
      },
      "source": [
        "Name: 이운규\n",
        "\n",
        "ID: 2016320145\n",
        "\n",
        "Link to your midterm project: https://colab.research.google.com/drive/1_ShNVJovC-oJ4nq52ObupMA0eo8geetV?usp=sharing\n",
        "\n",
        "Link to your evaluation script: https://colab.research.google.com/drive/1LlKl_8uCnjwjc5LMd0zm2O9oSr-Ub4lV?usp=sharing\n",
        "\n",
        "These links should be shared to the web without any permission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7ROjSdmSlcq"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split,KFold,cross_val_score,GridSearchCV,RandomizedSearchCV\n",
        "from google.colab import drive\n",
        "from pandas import DataFrame\n",
        "drive.mount('/content/drive/')\n",
        "a =0\n",
        "filename = '/content/drive/My Drive/뇌및머신러닝/train_data.csv'\n",
        "data = pd.read_csv(filename)\n",
        "\n",
        "data.head()\n",
        "\n",
        "evaluation_data_path = '/content/drive/My Drive/뇌및머신러닝/sample_evaluation_data.csv'\n",
        "cls_weight_path = '/content/drive/My Drive/뇌및머신러닝/cls_model.pkl'\n",
        "reg_weight_path1 = '/content/drive/My Drive/뇌및머신러닝/reg_model_1.pkl'\n",
        "reg_weight_path2 = '/content/drive/My Drive/뇌및머신러닝/reg_model_2.pkl'\n",
        "reg_weight_path3 = '/content/drive/My Drive/뇌및머신러닝/reg_model_3.pkl'\n",
        "\n",
        "# data = pd.read_csv(evaluation_data_path)\n",
        "X=data.drop(columns=['DX_bl','ADAS11','ADAS13','MMSE'],axis=1) #Predictors\n",
        "# y=data['DX_bl'] #Response\n",
        "col_list=X.columns.values.tolist()\n",
        "print(col_list)\n",
        "# X = X.interpolate(method='linear')\n",
        "# y1=data['ADAS11'] #Response\n",
        "# y2=data['ADAS13']\n",
        "# y3=data['MMSE']\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y1, test_size=0.1,random_state = 4)\n",
        "\n",
        "\n",
        "svc = pickle.load(open(cls_weight_path, 'rb'))\n",
        "\n",
        "rfr1 = pickle.load(open(reg_weight_path1, 'rb'))\n",
        "rfr2 = pickle.load(open(reg_weight_path2, 'rb'))\n",
        "rfr3 = pickle.load(open(reg_weight_path3, 'rb'))\n",
        "# rfr_pred= rfr.predict(X)\n",
        "# print(rfr_pred)\n",
        "# print('RandomForestRegressor')\n",
        "# print('MAE:', metrics.mean_absolute_error(y_test, rfr_pred))\n",
        "# print('MSE:', metrics.mean_squared_error(y_test, rfr_pred))\n",
        "# print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, rfr_pred)))\n",
        "\n",
        "# score=cross_val_score(rfr,X_train,y_train,cv=10)\n",
        "# print(score)\n",
        "# avscore = np.mean(score)\n",
        "# print('average train score: ',avscore)\n",
        "\n",
        "def load_best_classifier():\n",
        "    model = svc\n",
        "    \n",
        "    # Write your load function for classifier model here\n",
        "    # model = \n",
        "\n",
        "    return model\n",
        "\n",
        "def load_best_regressor():\n",
        "    model = (rfr1,rfr2,rfr3)\n",
        "\n",
        "    # Write your load function for regression model here\n",
        "    # model = \n",
        "\n",
        "    return model \n",
        "\n",
        "def read_csv_and_classify(eval_data, cls_model):\n",
        "    eval_data = eval_data[:,:140]\n",
        "    eval_data = pd.DataFrame(data=eval_data,columns=col_list)\n",
        "    eval_data=eval_data.interpolate()\n",
        "    eval_data=eval_data[['ST116CV', 'ST23CV', 'ST24CV', 'ST44CV', 'ST83CV', 'ST91CV', 'ST24TA',\n",
        "       'ST31TA', 'ST32TA', 'ST35TA', 'ST40TA', 'ST64TA', 'ST83TA', 'ST91TA',\n",
        "       'ST99TA']]\n",
        "    #print(eval_data)\n",
        "    scores = np.zeros(shape=len(eval_data), dtype=np.uint8)\n",
        "    scores = cls_model.predict(eval_data)\n",
        "    print(scores.dtype)\n",
        "    scores = scores.astype(np.uint8)\n",
        "    # Write your evaluation script here\n",
        "    # scores = \n",
        "\n",
        "    return scores # Should be a numpy array with shape=(len(eval_data), 1) and data type=np.uint8\n",
        "\n",
        "def read_csv_and_regress(eval_data, reg_model):\n",
        "    eval_data = eval_data[:,:140]\n",
        "    eval_data = pd.DataFrame(data=eval_data,columns=col_list)\n",
        "    eval_data=eval_data.interpolate()\n",
        "    # eval_data=eval_data[['ST116CV', 'ST23CV', 'ST24CV', 'ST44CV', 'ST83CV', 'ST91CV', 'ST24TA',\n",
        "    #    'ST31TA', 'ST32TA', 'ST35TA', 'ST40TA', 'ST64TA', 'ST83TA', 'ST91TA',\n",
        "    #    'ST99TA']]\n",
        "    scores = np.zeros(shape=(len(eval_data), 3), dtype=np.float32)\n",
        "    \n",
        "    scores1 = reg_model[0].predict(eval_data)\n",
        "    print(scores1)\n",
        "    \n",
        "    scores2 = reg_model[1].predict(eval_data)\n",
        "   \n",
        "    scores3 = reg_model[2].predict(eval_data)\n",
        "    scores = np.array([scores1,scores2,scores3])\n",
        "   \n",
        "    scores = scores.reshape(3, len(eval_data))\n",
        "    scores = scores.T\n",
        "    scores = scores.astype(np.float32)\n",
        "    \n",
        "    # Write your evaluation script here\n",
        "    # scores = \n",
        "\n",
        "    return scores # Should be a numpy array with shape=(len(eval_data), 3) and data type=np.float32\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        " \n",
        "# Load Data\n",
        "with open(evaluation_data_path, \"r\") as f:\n",
        "    eval_lines = f.read().strip().split(\"\\n\")\n",
        "    eval_header = eval_lines[0]\n",
        "    eval_data = eval_lines[1:]\n",
        "eval_data = np.array([[ff  if ff!=\"\" else \"nan\" for ff in fff.strip().split(\",\")] for fff in eval_data], dtype=np.float32)\n",
        " \n",
        "# Load Weights\n",
        "best_classification_model = load_best_classifier()\n",
        "best_regression_model = load_best_regressor()\n",
        " \n",
        "# Calculate scores\n",
        "cls_scores = read_csv_and_classify(eval_data[:, 4:], best_classification_model)\n",
        "reg_scores = read_csv_and_regress(eval_data[:, 4:], best_regression_model)\n",
        " \n",
        "# Check scores\n",
        "assert cls_scores.shape==(len(eval_data),), \"Classification score shape mismatch\"\n",
        "assert reg_scores.shape==(len(eval_data),3), \"Regression score shape mismatch\"\n",
        "assert cls_scores.dtype==np.uint8, \"Classification score data type mismatch\"\n",
        "assert reg_scores.dtype==np.float32, \"Regression score data type mismatch\"\n",
        " \n",
        "# Save and download scores\n",
        "eval_data[:, 0] = cls_scores\n",
        "eval_data[:, 1:4] = reg_scores\n",
        " \n",
        "with open(evaluation_data_path, \"w\") as f:\n",
        "    f.write(eval_header+\"\\n\"+\"\\n\".join([\",\".join([str(ff) for ff in fff]) for fff in eval_data]))\n",
        " \n",
        "files.download(evaluation_data_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyGWdoa6I8Nc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00NiTeYuRtlD"
      },
      "source": [
        ""
      ]
    }
  ]
}
